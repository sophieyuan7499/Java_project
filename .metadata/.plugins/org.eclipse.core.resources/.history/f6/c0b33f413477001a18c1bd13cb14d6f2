import org.apache.spark.sql.SparkSession
import org.apache.spark.SparkContext


object hm01 {
  def main(args: Array[String]): Unit = {
     val sparkSession = SparkSession.builder.master("local").appName("example").getOrCreate()
     import sparkSession.implicits._
     val lines = sparkSession.read.text("D://datas/spark/wordcount.txt").as[String];
    
  
     val words = lines.map(_.drop(2).toLowerCase()).flatMap(_.split(" ")) ;
      words.collect().foreach(println);
  }
}