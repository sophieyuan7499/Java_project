import org.apache.spark.SparkConf
import org.apache.spark.SparkContext


object hm01 {
  def main(args: Array[String]): Unit = {
     val conf =new SparkConf().setAppName("Test01").setMaster("local[2]");
    val sc=new SparkContext(conf);
    val lines=sc.textFile("D://datas/spark/wordcount.txt");
    
  
     val words = lines.map(_.drop(2).toLowerCase()).flatMap(_.split(" "));
      words.collect().foreach(println);
  }
}